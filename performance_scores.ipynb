{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74df5db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc31bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()): # running in colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    DATA_PATH = '/content/drive/MyDrive/revisiting_crossval_RNAfolding/'\n",
    "else:\n",
    "    DATA_PATH = '../shared_insync/revisiting_crossval_RNAfolding/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad66b7e",
   "metadata": {},
   "source": [
    "## Computing performance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549ff6f0",
   "metadata": {},
   "source": [
    "Scoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0867b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tp(bp_x, bp_ref, strict):\n",
    "    tp = 0\n",
    "    for rbp in bp_x:\n",
    "        cond = rbp in bp_ref\n",
    "        if not strict:\n",
    "            cond = cond or [rbp[0], rbp[1] - 1] in bp_ref or [rbp[0], rbp[1] + 1] in bp_ref or [rbp[0] + 1, rbp[1]] in bp_ref or [rbp[0] - 1, rbp[1]] in bp_ref\n",
    "        if cond:\n",
    "            tp += 1\n",
    "    return tp   \n",
    "\n",
    "def bp_metrics(ref_bp, pre_bp, strict=True):\n",
    "    \"\"\"F1, recall and precision score from base pairs. Is the same as triangular but less efficient. strict=False takes into account the  neighbors for each base pair as correct\"\"\"\n",
    "    assert all([type(bp) == list for bp in ref_bp]), \"ref_bp must be a list of lists\"\n",
    "    assert all([type(bp) == list for bp in pre_bp]), \"pre_bp must be a list of lists\"\n",
    "\n",
    "    # corner case when there are no positives\n",
    "    if len(ref_bp) == 0 and len(pre_bp) == 0:\n",
    "        return 1.0, 1.0, 1.0\n",
    "\n",
    "    tp1 = get_tp(pre_bp, ref_bp, strict)\n",
    "    tp2 = get_tp(ref_bp, pre_bp, strict)\n",
    "\n",
    "    fn = len(ref_bp) - tp1\n",
    "    fp = len(pre_bp) - tp1\n",
    "\n",
    "    tpr = pre = f1 = 0.0\n",
    "    if tp1 + fn > 0:\n",
    "        tpr = tp1 / float(tp1 + fn)  # sensitivity (=recall =power)\n",
    "    if tp1 + fp > 0:\n",
    "        pre = tp2 / float(tp1 + fp)  # precision (=ppv)\n",
    "    if tpr + pre > 0:\n",
    "        f1 = 2 * pre * tpr / (pre + tpr)  # F1 score\n",
    "\n",
    "    return f1, tpr, pre\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8969f73a",
   "metadata": {},
   "source": [
    "Reference dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03fa8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "      <th>len</th>\n",
       "      <th>structure</th>\n",
       "      <th>base_pairs</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5s_Acholeplasma-laidlawii-1</th>\n",
       "      <td>UCUGGUGACGAUAGGUAAGAUGGUUCACCUGUUCCCAUCCCGAACA...</td>\n",
       "      <td>112</td>\n",
       "      <td>((((((((......((((((((....((((((.............)...</td>\n",
       "      <td>[[1, 111], [2, 110], [3, 109], [4, 108], [5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5s_Acidovorax-temperans-1</th>\n",
       "      <td>UGCCUGAUGACCAUAGCAAGUUGGUACCACUCCUUCCCAUCCCGAA...</td>\n",
       "      <td>115</td>\n",
       "      <td>.(((((((((.....((((((((.....((((((...............</td>\n",
       "      <td>[[2, 115], [3, 114], [4, 113], [5, 112], [6, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tmRNA_Stre.gord._TRW-29390_1-349</th>\n",
       "      <td>GGGGUCGUUACGGAUUCGACAGGCAUUAUGAGGCAUAUUUUGCGAC...</td>\n",
       "      <td>349</td>\n",
       "      <td>(((((((............((((((((....(((((((((..((((...</td>\n",
       "      <td>[[1, 345], [2, 344], [3, 343], [4, 342], [5, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tRNA_tdbR00000055-Schizosaccharomyces_pombe-4896-Glu-3UC</th>\n",
       "      <td>UCCGUUGUGGUCCAACGGCUAGGAUUCGUCGCUUUCACCGACGGGA...</td>\n",
       "      <td>75</td>\n",
       "      <td>(((((((..((((........))))((((((.......)))))).....</td>\n",
       "      <td>[[1, 71], [2, 70], [3, 69], [4, 68], [5, 67], ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>srp_List.mono._U15684</th>\n",
       "      <td>UGGGUUGAUGAGCGUGAAGCCUUCGCUCGGUUGGAUUUUUCUUCAU...</td>\n",
       "      <td>279</td>\n",
       "      <td>.(.((((...(.(.((.(.((..(.....)..)).)...(...(.....</td>\n",
       "      <td>[[2, 276], [4, 274], [5, 273], [6, 272], [7, 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             sequence  \\\n",
       "id                                                                                                      \n",
       "5s_Acholeplasma-laidlawii-1                         UCUGGUGACGAUAGGUAAGAUGGUUCACCUGUUCCCAUCCCGAACA...   \n",
       "5s_Acidovorax-temperans-1                           UGCCUGAUGACCAUAGCAAGUUGGUACCACUCCUUCCCAUCCCGAA...   \n",
       "tmRNA_Stre.gord._TRW-29390_1-349                    GGGGUCGUUACGGAUUCGACAGGCAUUAUGAGGCAUAUUUUGCGAC...   \n",
       "tRNA_tdbR00000055-Schizosaccharomyces_pombe-489...  UCCGUUGUGGUCCAACGGCUAGGAUUCGUCGCUUUCACCGACGGGA...   \n",
       "srp_List.mono._U15684                               UGGGUUGAUGAGCGUGAAGCCUUCGCUCGGUUGGAUUUUUCUUCAU...   \n",
       "\n",
       "                                                    len  \\\n",
       "id                                                        \n",
       "5s_Acholeplasma-laidlawii-1                         112   \n",
       "5s_Acidovorax-temperans-1                           115   \n",
       "tmRNA_Stre.gord._TRW-29390_1-349                    349   \n",
       "tRNA_tdbR00000055-Schizosaccharomyces_pombe-489...   75   \n",
       "srp_List.mono._U15684                               279   \n",
       "\n",
       "                                                                                            structure  \\\n",
       "id                                                                                                      \n",
       "5s_Acholeplasma-laidlawii-1                         ((((((((......((((((((....((((((.............)...   \n",
       "5s_Acidovorax-temperans-1                           .(((((((((.....((((((((.....((((((...............   \n",
       "tmRNA_Stre.gord._TRW-29390_1-349                    (((((((............((((((((....(((((((((..((((...   \n",
       "tRNA_tdbR00000055-Schizosaccharomyces_pombe-489...  (((((((..((((........))))((((((.......)))))).....   \n",
       "srp_List.mono._U15684                               .(.((((...(.(.((.(.((..(.....)..)).)...(...(.....   \n",
       "\n",
       "                                                                                           base_pairs  \n",
       "id                                                                                                     \n",
       "5s_Acholeplasma-laidlawii-1                         [[1, 111], [2, 110], [3, 109], [4, 108], [5, 1...  \n",
       "5s_Acidovorax-temperans-1                           [[2, 115], [3, 114], [4, 113], [5, 112], [6, 1...  \n",
       "tmRNA_Stre.gord._TRW-29390_1-349                    [[1, 345], [2, 344], [3, 343], [4, 342], [5, 3...  \n",
       "tRNA_tdbR00000055-Schizosaccharomyces_pombe-489...  [[1, 71], [2, 70], [3, 69], [4, 68], [5, 67], ...  \n",
       "srp_List.mono._U15684                               [[2, 276], [4, 274], [5, 273], [6, 272], [7, 2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(f\"{DATA_PATH}data/archiveII_250808.csv\", index_col=\"id\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a21468",
   "metadata": {},
   "source": [
    "Classical methods are not trained, therefore the score per sequence is the same in all cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90218cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IPKnot LinearFoldV LinearPartitionC LinearPartitionV ProbKnot RNAfold RNAstructure "
     ]
    }
   ],
   "source": [
    "classical_methods = [\"IPKnot\", \"LinearFoldV\", \"LinearPartitionC\", \"LinearPartitionV\", \"ProbKnot\", \"RNAfold\", \"RNAstructure\"] \n",
    "trained_methods = [\"MxFold2\", \"REDfold\", \"UFold\", \"sincFold\"]\n",
    "\n",
    "# load predictions and compute f1 scores\n",
    "classical_summary = []\n",
    "for method in classical_methods:\n",
    "    print(method, end=\" \")\n",
    "    pred = pd.read_csv(DATA_PATH+f\"results/{method}.csv\", index_col=\"id\")\n",
    "    pred[\"ref\"] = dataset.loc[pred.index, \"base_pairs\"]\n",
    "    pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "    pred[\"method\"] = method\n",
    "    pred = pred[[\"method\", \"f1\", \"rec\", \"pre\"]]\n",
    "    classical_summary.append(pred)\n",
    "classical_summary = pd.concat(classical_summary)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed5ae20",
   "metadata": {},
   "source": [
    "### Random k-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be33bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fold_number</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             partition\n",
       "fold_number           \n",
       "0                 3864\n",
       "1                 3864\n",
       "2                 3864\n",
       "3                 3864\n",
       "4                 3864"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_name = \"1_random_kfolds\"\n",
    "splits = pd.read_csv(f\"{DATA_PATH}data/{partition_name}/split.csv\", index_col=\"id\")\n",
    "splits.groupby(\"fold_number\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f313a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MxFold2 REDfold UFold sincFold \n",
      "1 MxFold2 REDfold UFold sincFold \n",
      "2 MxFold2 REDfold UFold sincFold \n",
      "3 MxFold2 REDfold UFold sincFold \n",
      "4 MxFold2 REDfold UFold sincFold \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folds = sorted(splits[\"fold_number\"].unique())\n",
    "summary = []\n",
    "for fold in folds:\n",
    "    partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "    print(fold, end=\" \")\n",
    "    for method in trained_methods:\n",
    "        f = DATA_PATH+f\"results/{partition_name}/{method}/{fold}/pred.csv\"\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"\\n{method, fold} not found, skipping\\n\")\n",
    "            continue\n",
    "        print(method, end=\" \")\n",
    "        \n",
    "        pred = pd.read_csv(f, index_col=\"id\")\n",
    "        pred[\"ref\"] = dataset.loc[partition_set.index, \"base_pairs\"]\n",
    "        pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "        pred[\"method\"] = method\n",
    "        pred[\"fold\"] = fold\n",
    "        pred = pred[[\"method\", \"fold\", \"f1\", \"rec\", \"pre\"]]\n",
    "        summary.append(pred)\n",
    "    print()\n",
    "summary = pd.concat(summary)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440d372a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MxFold2', 'REDfold', 'UFold', 'sincFold', 'IPKnot', 'LinearFoldV',\n",
       "       'LinearPartitionC', 'LinearPartitionV', 'ProbKnot', 'RNAfold',\n",
       "       'RNAstructure'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add classical methods to kfold summary\n",
    "for method in classical_methods:\n",
    "    for fold in folds:\n",
    "        partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "        res = classical_summary.loc[partition_set.index]\n",
    "        res = res[res[\"method\"] == method]\n",
    "        res[\"fold\"] = fold\n",
    "        summary = pd.concat([summary, res])\n",
    "\n",
    "os.makedirs(\"results\", exist_ok=True) \n",
    "summary.to_csv(f\"results/{partition_name}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d01486",
   "metadata": {},
   "source": [
    "### Fam-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dfa55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_name = \"2_fam_folds\"\n",
    "splits = pd.read_csv(f\"{DATA_PATH}data/{partition_name}/split.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be76a31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MxFold2 REDfold UFold sincFold \n",
      "1 MxFold2 REDfold UFold sincFold \n",
      "2 MxFold2 REDfold UFold sincFold \n",
      "3 MxFold2 REDfold UFold sincFold \n",
      "4 MxFold2 REDfold UFold sincFold \n",
      "5 MxFold2 REDfold UFold sincFold \n",
      "6 MxFold2 REDfold UFold sincFold \n",
      "7 MxFold2 REDfold UFold sincFold \n",
      "8 MxFold2 REDfold UFold sincFold \n"
     ]
    }
   ],
   "source": [
    "folds = sorted(splits[\"fold_number\"].unique())\n",
    "summary = []\n",
    "for fold in folds:\n",
    "    partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "    print(fold, end=\" \")\n",
    "    for method in trained_methods:\n",
    "        f = DATA_PATH+f\"results/{partition_name}/{method}/{fold}/pred.csv\"\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"\\n{method, fold} not found, skipping\\n\")\n",
    "            continue\n",
    "        print(method, end=\" \")\n",
    "        \n",
    "        pred = pd.read_csv(f, index_col=\"id\")\n",
    "        pred[\"ref\"] = dataset.loc[partition_set.index, \"base_pairs\"]\n",
    "        pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "        pred[\"method\"] = method\n",
    "        pred[\"fold\"] = fold\n",
    "        pred = pred[[\"method\", \"fold\", \"f1\", \"rec\", \"pre\"]]\n",
    "        summary.append(pred)\n",
    "    print()\n",
    "summary = pd.concat(summary)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84ddecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classical methods to the summary\n",
    "for method in classical_methods:\n",
    "    for fold in folds:\n",
    "        partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "        res = classical_summary.loc[partition_set.index]\n",
    "        res = res[res[\"method\"] == method]\n",
    "        res[\"fold\"] = fold\n",
    "        summary = pd.concat([summary, res])\n",
    "os.makedirs(\"results\", exist_ok=True) \n",
    "summary.to_csv(f\"results/{partition_name}.csv\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d81494",
   "metadata": {},
   "source": [
    "### Clustering folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "089c1214",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_name = \"3_clustering_folds\"\n",
    "splits = pd.read_csv(f\"{DATA_PATH}data/{partition_name}/split.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9703b775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 MxFold2 REDfold UFold sincFold \n",
      "1 MxFold2 REDfold UFold sincFold \n",
      "2 MxFold2 REDfold UFold sincFold \n",
      "3 MxFold2 REDfold UFold sincFold \n",
      "4 MxFold2 REDfold UFold sincFold \n"
     ]
    }
   ],
   "source": [
    "folds = sorted(splits[\"fold_number\"].unique())\n",
    "summary = []\n",
    "for fold in folds:\n",
    "    partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "    print(fold, end=\" \")\n",
    "    for method in trained_methods:\n",
    "        f = DATA_PATH+f\"results/{partition_name}/{method}/{fold}/pred.csv\"\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"\\n{method, fold} not found, skipping\\n\")\n",
    "            continue\n",
    "        print(method, end=\" \")\n",
    "        \n",
    "        pred = pd.read_csv(f, index_col=\"id\")\n",
    "        pred[\"ref\"] = dataset.loc[partition_set.index, \"base_pairs\"]\n",
    "        pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "        pred[\"method\"] = method\n",
    "        pred[\"fold\"] = fold\n",
    "        pred = pred[[\"method\", \"fold\", \"f1\", \"rec\", \"pre\"]]\n",
    "        summary.append(pred)\n",
    "    print()\n",
    "summary = pd.concat(summary)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a619db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classical methods to the summary\n",
    "for method in classical_methods:\n",
    "    for fold in folds:\n",
    "        partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "        res = classical_summary.loc[partition_set.index]\n",
    "        res = res[res[\"method\"] == method]\n",
    "        res[\"fold\"] = fold\n",
    "        summary = pd.concat([summary, res])\n",
    "os.makedirs(\"results\", exist_ok=True) \n",
    "summary.to_csv(f\"results/{partition_name}.csv\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15db22f",
   "metadata": {},
   "source": [
    "### HL folds\n",
    "- sincFold TODO\n",
    "- mxfold2 h5 missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72c2feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_name = \"5_hl_folds\"\n",
    "splits = pd.read_csv(f\"{DATA_PATH}data/{partition_name}/split.csv\", index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad01cbac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hl10 MxFold2 REDfold UFold sincFold \n",
      "hl15 MxFold2 REDfold UFold sincFold \n",
      "hl20 MxFold2 REDfold UFold sincFold \n",
      "hl25 MxFold2 REDfold UFold sincFold \n",
      "hl30 MxFold2 REDfold UFold sincFold \n",
      "hl35 MxFold2 REDfold UFold sincFold \n",
      "hl40 MxFold2 REDfold UFold sincFold \n",
      "hl45 MxFold2 REDfold UFold sincFold \n",
      "hl50 MxFold2 REDfold UFold sincFold \n",
      "hl55 MxFold2 REDfold UFold sincFold \n",
      "hl60 MxFold2 REDfold UFold sincFold \n",
      "hl65 MxFold2 REDfold UFold sincFold \n",
      "hl70 MxFold2 REDfold UFold sincFold \n",
      "hl75 MxFold2 REDfold UFold sincFold \n",
      "hl80 MxFold2 REDfold UFold sincFold \n",
      "hl85 MxFold2 REDfold UFold sincFold \n",
      "hl90 MxFold2 REDfold UFold sincFold \n",
      "hl95 MxFold2 REDfold UFold sincFold \n"
     ]
    }
   ],
   "source": [
    "folds = sorted(splits[\"fold_name\"].unique())\n",
    "summary = []\n",
    "for fold in folds:\n",
    "    partition_set = splits[(splits[\"fold_name\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "    print(fold, end=\" \")\n",
    "    for method in trained_methods:\n",
    "        f = DATA_PATH+f\"results/{partition_name}/{method}/{fold}/pred.csv\"\n",
    "        if not os.path.exists(f):\n",
    "            print(f\"\\n{method, fold} not found, skipping\\n\")\n",
    "            continue\n",
    "        print(method, end=\" \")\n",
    "        \n",
    "        pred = pd.read_csv(f, index_col=\"id\")\n",
    "        pred[\"ref\"] = dataset.loc[partition_set.index, \"base_pairs\"]\n",
    "        pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "        pred[\"method\"] = method\n",
    "        pred[\"fold\"] = fold\n",
    "        pred = pred[[\"method\", \"fold\", \"f1\", \"rec\", \"pre\"]]\n",
    "        summary.append(pred)\n",
    "    print()\n",
    "summary = pd.concat(summary)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cdd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classical methods to the summary\n",
    "for method in classical_methods:\n",
    "    for fold in folds:\n",
    "        partition_set = splits[(splits[\"fold_name\"] == fold) & (splits[\"partition\"] == \"test\")]\n",
    "        res = classical_summary.loc[partition_set.index]\n",
    "        res = res[res[\"method\"] == method]\n",
    "        res[\"fold\"] = fold\n",
    "        summary = pd.concat([summary, res])\n",
    "summary.method.unique()    \n",
    "os.makedirs(\"results\", exist_ok=True) \n",
    "summary.to_csv(f\"results/{partition_name}.csv\")       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894874b7",
   "metadata": {},
   "source": [
    "### SIM folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164481a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_name</th>\n",
       "      <th>fold_number</th>\n",
       "      <th>partition</th>\n",
       "      <th>id</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>grp1_a.I1.m.M.grisea.B2.ND1</td>\n",
       "      <td>sim70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>srp_Pyro.aero._AE009852</td>\n",
       "      <td>sim70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>RNaseP_vHge3-5</td>\n",
       "      <td>sim70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>telomerase_AF221924.105-538</td>\n",
       "      <td>sim70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>srp_Mono.brev._GSP-81824</td>\n",
       "      <td>sim70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_name  fold_number partition                           id similarity\n",
       "0          0            0     train  grp1_a.I1.m.M.grisea.B2.ND1      sim70\n",
       "1          0            0     train      srp_Pyro.aero._AE009852      sim70\n",
       "2          0            0     train               RNaseP_vHge3-5      sim70\n",
       "3          0            0     train  telomerase_AF221924.105-538      sim70\n",
       "4          0            0     train     srp_Mono.brev._GSP-81824      sim70"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partition_name = \"6_sim_folds\"\n",
    "splits = []\n",
    "for f in os.listdir(f\"{DATA_PATH}data/6_sim_folds/bootstrap/\"):\n",
    "    split = pd.read_csv(f\"{DATA_PATH}data/6_sim_folds/bootstrap/{f}\")\n",
    "    split[\"similarity\"] = f.split(\"_\")[-1].split(\"-\")[0]                    \n",
    "    splits.append(split) \n",
    "splits = pd.concat(splits)\n",
    "splits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "99128eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim30 0 MxFold2 "
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([4], dtype='int64')] are in the [index]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(method, end=\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m pred = pd.read_csv(f, index_col=\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m pred[\u001b[33m\"\u001b[39m\u001b[33mref\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpartition_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbase_pairs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     18\u001b[39m pred[[\u001b[33m\"\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mrec\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpre\u001b[39m\u001b[33m\"\u001b[39m]] = pred.apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: bp_metrics(json.loads(x[\u001b[33m\"\u001b[39m\u001b[33mref\u001b[39m\u001b[33m\"\u001b[39m]), json.loads(x[\u001b[33m\"\u001b[39m\u001b[33mbase_pairs\u001b[39m\u001b[33m\"\u001b[39m])), axis=\u001b[32m1\u001b[39m, result_type=\u001b[33m\"\u001b[39m\u001b[33mexpand\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     19\u001b[39m pred[\u001b[33m\"\u001b[39m\u001b[33msimilarity\u001b[39m\u001b[33m\"\u001b[39m] = similarity\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1184\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1182\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_scalar_access(key):\n\u001b[32m   1183\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._get_value(*key, takeable=\u001b[38;5;28mself\u001b[39m._takeable)\n\u001b[32m-> \u001b[39m\u001b[32m1184\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_tuple\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1185\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1186\u001b[39m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n\u001b[32m   1187\u001b[39m     axis = \u001b[38;5;28mself\u001b[39m.axis \u001b[38;5;129;01mor\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1368\u001b[39m, in \u001b[36m_LocIndexer._getitem_tuple\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1366\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m suppress(IndexingError):\n\u001b[32m   1367\u001b[39m     tup = \u001b[38;5;28mself\u001b[39m._expand_ellipsis(tup)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_lowerdim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[38;5;66;03m# no multi-index, so validate all of the indexers\u001b[39;00m\n\u001b[32m   1371\u001b[39m tup = \u001b[38;5;28mself\u001b[39m._validate_tuple_indexer(tup)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1089\u001b[39m, in \u001b[36m_LocationIndexer._getitem_lowerdim\u001b[39m\u001b[34m(self, tup)\u001b[39m\n\u001b[32m   1087\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m section\n\u001b[32m   1088\u001b[39m         \u001b[38;5;66;03m# This is an elided recursive call to iloc/loc\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_key\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m IndexingError(\u001b[33m\"\u001b[39m\u001b[33mnot applicable\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1420\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1417\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key.ndim > \u001b[32m1\u001b[39m:\n\u001b[32m   1418\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index with multidimensional key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1420\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_iterable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1422\u001b[39m \u001b[38;5;66;03m# nested tuple slicing\u001b[39;00m\n\u001b[32m   1423\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_nested_tuple(key, labels):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1360\u001b[39m, in \u001b[36m_LocIndexer._getitem_iterable\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1357\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m   1359\u001b[39m \u001b[38;5;66;03m# A collection of keys\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1360\u001b[39m keyarr, indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1361\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._reindex_with_indexers(\n\u001b[32m   1362\u001b[39m     {axis: [keyarr, indexer]}, copy=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_dups=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1363\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexing.py:1558\u001b[39m, in \u001b[36m_LocIndexer._get_listlike_indexer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1555\u001b[39m ax = \u001b[38;5;28mself\u001b[39m.obj._get_axis(axis)\n\u001b[32m   1556\u001b[39m axis_name = \u001b[38;5;28mself\u001b[39m.obj._get_axis_name(axis)\n\u001b[32m-> \u001b[39m\u001b[32m1558\u001b[39m keyarr, indexer = \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1560\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m keyarr, indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexes/base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/sincfold_utils/lib/python3.11/site-packages/pandas/core/indexes/base.py:6261\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6259\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m nmissing:\n\u001b[32m   6260\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m nmissing == \u001b[38;5;28mlen\u001b[39m(indexer):\n\u001b[32m-> \u001b[39m\u001b[32m6261\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m     not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m   6264\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"None of [Index([4], dtype='int64')] are in the [index]\""
     ]
    }
   ],
   "source": [
    "similarities = sorted(splits[\"similarity\"].unique())\n",
    "folds = sorted(splits[\"fold_number\"].unique())\n",
    "summary = []\n",
    "for similarity in similarities:\n",
    "    print(similarity, end=\" \")\n",
    "    for fold in folds:\n",
    "        partition_set = splits[(splits[\"fold_number\"] == fold) & (splits[\"similarity\"] == similarity) & (splits[\"partition\"] == \"test\")]\n",
    "        print(fold, end=\" \")\n",
    "        for method in trained_methods:\n",
    "            f = DATA_PATH+f\"results/{partition_name}/{method}/{similarity}/{fold}/pred.csv\"\n",
    "            if not os.path.exists(f):\n",
    "                print(f\"\\n{method, fold} not found, skipping\\n\")\n",
    "                continue\n",
    "            print(method, end=\" \")\n",
    "            \n",
    "            pred = pd.read_csv(f, index_col=\"id\")\n",
    "            pred[\"ref\"] = dataset.loc[partition_set.index, \"base_pairs\"]\n",
    "            pred[[\"f1\", \"rec\", \"pre\"]] = pred.apply(lambda x: bp_metrics(json.loads(x[\"ref\"]), json.loads(x[\"base_pairs\"])), axis=1, result_type=\"expand\")\n",
    "            pred[\"similarity\"] = similarity\n",
    "            pred[\"method\"] = method\n",
    "            pred[\"fold\"] = fold\n",
    "            pred = pred[[\"method\", \"similarity\", \"fold\", \"f1\", \"rec\", \"pre\"]]\n",
    "            summary.append(pred)\n",
    "        print()\n",
    "summary = pd.concat(summary)    \n",
    "summary.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
